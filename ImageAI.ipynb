{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageAI.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UVdH44Xb324uw1pVv9g7zavDElrGPQ4P","authorship_tag":"ABX9TyOo/81Rt8T7fLWyfPB83x8s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SqeWc_ipwROZ","colab_type":"text"},"source":["Runtime -> Change runtime type -> Hardware accelerator -> choose GPU"]},{"cell_type":"code","metadata":{"id":"49VCFKvp3eH1","colab_type":"code","colab":{}},"source":["#install the adequate version of TensorFlow\n","!pip3 install tensorflow-gpu==1.13.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"85K4jz4F3iyV","colab_type":"code","colab":{}},"source":["#install library for yolov3 utilisation\n","!pip3 install imageai --upgrade"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Nr7eOYE3lpa","colab_type":"code","colab":{}},"source":["#Download a pretrained version of a yolov3 model\n","!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkp791yz3znq","colab_type":"code","colab":{}},"source":["#unzip the datset of plates\n","!unzip plates.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9rAjmAL43Ar","colab_type":"code","outputId":"b7528819-2d1a-4697-c881-f5da7319d9f4","executionInfo":{"status":"ok","timestamp":1586941721455,"user_tz":-120,"elapsed":1229898,"user":{"displayName":"Raphael Mendes de Oliveira","photoUrl":"","userId":"11039410918448187550"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["#trains a YOLOv3 detection model\n","#data_ directory is the directory where our Pascal VOC dataset is saved (\"plates\" in this case)\n","#object_names_array is the list of objects we are detecting, i.e, the labels in the dataset\n","#num_experiments is the number of epochs we do\n","#batch_size is the batch size used\n","#train_from_pretrained_model is the path to model from which we start the training\n","\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"plates\")\n","trainer.setTrainConfig(object_names_array=[\"LP\"], batch_size=4, num_experiments=2, train_from_pretrained_model=\"plates/models/detection_model-ex-002--loss-0007.222.h5\")\n","trainer.trainModel()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.81\n","Anchor Boxes generated.\n","Detection configuration saved in  plates/json/detection_config.json\n","Training on: \t['LP']\n","Training with Batch Size:  4\n","Number of Experiments:  2\n","Training with transfer learning from pretrained Model\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n","456/456 [==============================] - 503s 1s/step - loss: 5.2914 - yolo_layer_7_loss: 1.0471 - yolo_layer_8_loss: 1.8413 - yolo_layer_9_loss: 2.4029 - val_loss: 2.2997 - val_yolo_layer_7_loss: 0.6518 - val_yolo_layer_8_loss: 1.7096 - val_yolo_layer_9_loss: 2.0167\n","Epoch 2/2\n","456/456 [==============================] - 423s 928ms/step - loss: 4.7402 - yolo_layer_7_loss: 0.7489 - yolo_layer_8_loss: 1.7989 - yolo_layer_9_loss: 2.1923 - val_loss: 2.3365 - val_yolo_layer_7_loss: 0.5851 - val_yolo_layer_8_loss: 1.5482 - val_yolo_layer_9_loss: 2.1256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kLEiVL3c5TcF","colab_type":"code","colab":{}},"source":["#Evaluates the models we have\n","#model_path is the path to where the models were saved\n","#json_path is the path to the detection_config.json file generated in the previous cell. It contains the anchors calculated\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"plates\")\n","trainer.evaluateModel(model_path=\"plates/models\", json_path=\"plates/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0gnYIuN97TG","colab_type":"code","outputId":"3bdc2aac-d98e-4036-b872-4a89231e95e4","executionInfo":{"status":"ok","timestamp":1586962006948,"user_tz":-120,"elapsed":32102,"user":{"displayName":"Raphael Mendes de Oliveira","photoUrl":"","userId":"11039410918448187550"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Usage of the model for prediction\n","#input_image is the path to the image where the detection is done\n","#output_image_path is the path to the saved image with the detections done \n","from imageai.Detection.Custom import CustomObjectDetection\n","\n","input_image=\"voiture2.jpg\"\n","output_image_path=\"voiture2-detected.jpg\"\n","\n","detector = CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(\"drive/My Drive/Colab Notebooks/plates/models/detection_model-ex-001--loss-0005.291.h5\") \n","detector.setJsonPath(\"drive/My Drive/Colab Notebooks/plates/json/detection_config.json\")\n","detector.loadModel()\n","detections = detector.detectObjectsFromImage(input_image, output_image_path)\n","for detection in detections:\n","    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n"],"execution_count":169,"outputs":[{"output_type":"stream","text":["LP  :  53.26648950576782  :  [70, 113, 149, 124]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RZm5Tqf4BL_l","colab_type":"code","colab":{}},"source":["#Getting localisations for the plates in the image\n","import numpy as np\n","import cv2\n","\n","def get_boxes(detections):\n","  boxes = []\n","  for detection in detections:\n","    boxes.append(detection[\"box_points\"])\n","  boxes = np.array(boxes)\n","  return boxes\n","\n","def cropped_plates(img_path, boxes, aug0=40,aug1=40,aug2=40,aug3=40):\n","  #increase boxes to deal with prediction's imprecision\n","  aug_boxes = np.array([-int(0.*aug0),int(aug1),-int(aug2),int(0.*aug3)])\n","  boxes += aug_boxes\n","  \n","  cropped_images = []\n","  img = cv2.imread(img_path) \n","  cv2.resize(img, (416,416))\n","  for box in boxes:\n","    #trying to fix bug of ImageAI\n","    # height, width = img.shape[:2]\n","    # for i in range(4):\n","    #   if i<2:\n","    #     box[i]*=width/416.\n","    #   else:\n","    #     box[i]*=height/416.\n","    cropped = img[int(box[2]):int(box[3]),int(box[0]):int(box[1])]\n","    print(box)\n","    cropped_images.append(cropped)\n","  \n","  return cropped_images\n","\n","#prints for debugging reasons\n","# boxes = get_boxes(detections)\n","# crp = cropped_plates(input_image,boxes)\n","# boxes\n","# cv2.imwrite('socorr.jpg', crp[0])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBrXFz311vKM","colab_type":"code","colab":{}},"source":["#API for reading text from image\n","!apt-get install tesseract-ocr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKvOe-jU19jg","colab_type":"code","colab":{}},"source":["#Install necessary libraries\n","!pip install pillow\n","!pip install pytesseract\n","!pip install opencv-python"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTMoN2wjJ5yQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d619d963-bbc2-4881-f343-76b97e3910bc","executionInfo":{"status":"ok","timestamp":1586964189959,"user_tz":-120,"elapsed":1527,"user":{"displayName":"Raphael Mendes de Oliveira","photoUrl":"","userId":"11039410918448187550"}}},"source":["import cv2\n","import os\n","import pytesseract\n","import numpy as np\n","\n","\n","#INTEGRATION FROM DETECTION TO READING\n","#get the boxes from the detection\n","boxes = get_boxes(detections)\n","crpd_plates = cropped_plates(img_path=input_image, boxes=boxes)\n","if not os.path.exists('cropped_images'):\n","        os.makedirs('cropped_images')\n","\n","# ipath=os.getcwd+\"\\\\0.jpg\"\n","def get_string(img_path, output_dir,img):\n","    # Extract the file name without the file extension\n","    file_name = os.path.basename(img_path).split('.')[0]\n","    file_name = file_name.split()[0]\n","\n","    # Create a directory for outputs\n","    output_path = os.path.join(output_dir, file_name)\n","    if not os.path.exists(output_path):\n","        os.makedirs(output_path)\n","    \n","    return file_name, output_path, img\n","\n","# img = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n","\n","def noise_removal(img):\n","    # Convert to gray\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply dilation and erosion to remove some noise\n","    kernel = np.ones((1, 1), np.uint8)\n","    img = cv2.dilate(img, kernel, iterations=1)\n","    img = cv2.erode(img, kernel, iterations=1)\n","    # Apply blur to smooth out the edges\n","    img = cv2.GaussianBlur(img, (5, 5), 0)\n","    \n","    return img\n","\n","def binarization(img):\n","    # Apply threshold to get image with only b&w (binarization)\n","    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","\n","    return img\n","def binarization_gaussian(img):\n","    img = cv2.adaptiveThreshold(img,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11,2)\n","    return img\n","\n","def save_result(img, output_path, file_name):\n","    # Save the filtered image in the output directory\n","    save_path = os.path.join(output_path, file_name + \"_filter.jpg\")\n","    cv2.imwrite(save_path, img)\n","\n","    # Recognize text with tesseract for python\n","    result = pytesseract.image_to_string(img, lang=\"eng\")\n","    return result\n","\n","#loop over the cropped images containing the plates\n","for i in range(len(crpd_plates)):\n","  img = crpd_plates[i]\n","  img = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n","  _, output_path, img = get_string('shot2.jpg', os.getcwd(),img) \n","  \n","  img1 = noise_removal(img)\n","  # cv2.imwrite('socorro1.jpg', img1)\n","  img2 = binarization_gaussian(img1)\n","  # cv2.imwrite('socorro2.jpg', img2)\n","  \n","  result = save_result(img2,output_path, \"plate_numbers\")\n","  if result=='':\n","    img1 = 255-img1\n","    img2 = binarization_gaussian(img1)\n","    # cv2.imwrite('socorr.jpg', img2)\n","  \n","    result = save_result(img1,output_path, \"plate_numbers\")\n","# print(result)\n","\n"],"execution_count":203,"outputs":[{"output_type":"stream","text":["[ 70 153 109 124]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6LmtV6K0xREi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2f61cbf7-c02e-47f1-e02c-04bb98c939f7","executionInfo":{"status":"ok","timestamp":1586964196363,"user_tz":-120,"elapsed":1116,"user":{"displayName":"Raphael Mendes de Oliveira","photoUrl":"","userId":"11039410918448187550"}}},"source":["result"],"execution_count":204,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'mA 737 AT i'"]},"metadata":{"tags":[]},"execution_count":204}]}]}